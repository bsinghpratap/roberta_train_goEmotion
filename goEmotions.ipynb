{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5acb76c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from os.path import join\n",
    "import multiprocessing as mp\n",
    "from importlib import reload\n",
    "from collections import Counter\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import (WEIGHTS_NAME,\n",
    "                          BertConfig, BertForSequenceClassification, BertTokenizer,\n",
    "                          XLMConfig, XLMForSequenceClassification, XLMTokenizer,\n",
    "                          DistilBertConfig, DistilBertForSequenceClassification, DistilBertTokenizer,\n",
    "                          RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)\n",
    "from transformers import BertPreTrainedModel, BertModel, AdamW, get_linear_schedule_with_warmup, AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af312fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class emotionDataset(Dataset):\n",
    "    \"\"\"Class to load the dataset and get batches of paras\"\"\"\n",
    "    \n",
    "    def __init__(self, list_data, \n",
    "                 tokenizer, max_length):\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.data = list_data\n",
    "        self.pad_token = 1\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Return length of dataset.\"\"\"\n",
    "        return self.data.__len__()\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"Return sample from dataset at index i.\"\"\"\n",
    "        example = self.data[i]\n",
    "        inputs = self.tokenizer.encode_plus(example['text'],\n",
    "                                            add_special_tokens=True,\n",
    "                                            truncation=True,\n",
    "                                            max_length=self.max_length)\n",
    "                \n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        input_ids = input_ids[:self.max_length]\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "        \n",
    "        padding_length = self.max_length - len(input_ids)\n",
    "        input_ids = input_ids + ([self.pad_token] * padding_length)\n",
    "        attention_mask = attention_mask + ([0] * padding_length)\n",
    "        \n",
    "        assert len(input_ids) == self.max_length, \"Error with input length {} vs {}\".format(len(input_ids), self.max_length)\n",
    "        \n",
    "        nli_label = example['labels'][0]\n",
    "        \n",
    "        return_dict = {'input_ids':torch.LongTensor(input_ids),\n",
    "                       'attention_mask':torch.LongTensor(attention_mask),\n",
    "                       'labels': torch.LongTensor([nli_label])}\n",
    "        \n",
    "        return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9966f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0:\"admiration\",\n",
    "            1:\"amusement\",\n",
    "            2:\"anger\",\n",
    "            3:\"annoyance\",\n",
    "            4:\"approval\",\n",
    "            5:\"caring\",\n",
    "            6:\"confusion\",\n",
    "            7:\"curiosity\",\n",
    "            8:\"desire\",\n",
    "            9:\"disappointment\",\n",
    "            10:\"disapproval\",\n",
    "            11:\"disgust\",\n",
    "            12:\"embarrassment\",\n",
    "            13:\"excitement\",\n",
    "            14:\"fear\",\n",
    "            15:\"gratitude\",\n",
    "            16:\"grief\",\n",
    "            17:\"joy\",\n",
    "            18:\"love\",\n",
    "            19:\"nervousness\",\n",
    "            20:\"optimism\",\n",
    "            21:\"pride\",\n",
    "            22:\"realization\",\n",
    "            23:\"relief\",\n",
    "            24:\"remorse\",\n",
    "            25:\"sadness\",\n",
    "            26:\"surprise\",\n",
    "            27:\"neutral\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21a6ac6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset go_emotions (/home/brawat/.cache/huggingface/datasets/go_emotions/simplified/0.0.0/2637cfdd4e64d30249c3ed2150fa2b9d279766bfcd6a809b9f085c61a90d776d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5125aed7d86347648035953454d386fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"go_emotions\", \"simplified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53fdf2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 36308, 2: 6541, 3: 532, 4: 28, 5: 1})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([x['labels'].__len__() for x in dataset['train']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "105d4f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation', 'test'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58d6eff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"My favourite food is anything I didn't have to cook myself.\",\n",
       " 'labels': [27],\n",
       " 'id': 'eebbqej'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf152183",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_config = RobertaConfig.from_pretrained('roberta-base',\n",
    "                                      num_labels=len(id2label),\n",
    "                                      finetuning_task='GoEmotions',\n",
    "                                      cache_dir=None,\n",
    "                                      output_attentions=False,\n",
    "                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17528cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75c42425",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = emotionDataset(list_data=dataset['train'], \n",
    "                               tokenizer=tokenizer, \n",
    "                               max_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c9597a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,\n",
    "                          num_workers=mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7f5ca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8ae8d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 200]), torch.Size([32, 200]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch['input_ids'].shape, example_batch['attention_mask'].shape, example_batch['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "568ffaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'weight_decay':0.0,\n",
    "        'learning_rate':2e-5,\n",
    "        'epochs':5,\n",
    "        'gradient_accumulation_steps':1,\n",
    "        'adam_epsilon':1e-8}\n",
    "args['t_total'] = len(train_loader) // args['gradient_accumulation_steps'] * args['epochs']\n",
    "args['warmup_steps'] = int(0.10*args['t_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52f0e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaForSequenceClassification(config=roberta_config).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a331471",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': args['weight_decay']},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=args['learning_rate'], eps=args['adam_epsilon'])\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args['warmup_steps'],\n",
    "                                            num_training_steps=args['t_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afd0d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.DataParallel(model.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "578037d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1357 [00:00<?, ?it/s]/home/brawat/miniconda3/envs/doc/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|██████████| 1357/1357 [07:50<00:00,  2.89it/s]\n",
      "100%|██████████| 1357/1357 [07:42<00:00,  2.94it/s]\n",
      "100%|██████████| 1357/1357 [07:45<00:00,  2.91it/s]\n",
      "100%|██████████| 1357/1357 [07:46<00:00,  2.91it/s]\n",
      "100%|██████████| 1357/1357 [07:45<00:00,  2.91it/s]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for each_epoch in range(args['epochs']):\n",
    "    for batch in tqdm(train_loader):\n",
    "        model.zero_grad()\n",
    "        outputs = model(**batch)\n",
    "        ### Loss calculation\n",
    "        loss = outputs[0].mean()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a96cdc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = emotionDataset(list_data=dataset['test'], \n",
    "                               tokenizer=tokenizer, \n",
    "                               max_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f99d222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=32, \n",
    "                         shuffle=False, num_workers=mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb025807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model_, eval_loader):\n",
    "    model.eval()\n",
    "    dict_result = {'actual':[],\n",
    "                   'preds':[]}\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(eval_loader):\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs[1]\n",
    "            \n",
    "            dict_result['actual'] += batch['labels'].numpy().tolist()\n",
    "            dict_result['preds'] += np.argmax(logits.detach().cpu().numpy(), axis=1).tolist()\n",
    "    return dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d840e8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:27<00:00,  6.22it/s]\n"
     ]
    }
   ],
   "source": [
    "dict_test_results = evaluate(model_=model,\n",
    "                             eval_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b62151a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(actual_og, preds_og, dict_mapping, avoid_labels=[]):\n",
    "    actual_og = [x[0] for x in actual_og]\n",
    "    actual_ = []\n",
    "    preds_ = []\n",
    "    for ind in tqdm(range(actual_og.__len__())):\n",
    "        if actual_og[ind] not in avoid_labels and preds_og[ind] not in avoid_labels:\n",
    "            actual_.append(actual_og[ind])\n",
    "            preds_.append(preds_og[ind])\n",
    "    df_report = classification_report(actual_, preds_)\n",
    "    print(df_report)\n",
    "    print('--'*20)\n",
    "    print('STATS')\n",
    "    print('--'*20)\n",
    "    print('Actual counter:', Counter(actual_))\n",
    "    print('Prediction counter:', Counter(preds_))\n",
    "    print('Mapping:', dict_mapping)\n",
    "    return df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "57f7cd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5427/5427 [00:00<00:00, 1191503.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.63      0.62       504\n",
      "           1       0.70      0.87      0.78       252\n",
      "           2       0.45      0.43      0.44       197\n",
      "           3       0.26      0.20      0.22       286\n",
      "           4       0.34      0.29      0.31       318\n",
      "           5       0.29      0.21      0.24       114\n",
      "           6       0.31      0.28      0.29       139\n",
      "           7       0.46      0.50      0.48       233\n",
      "           8       0.51      0.34      0.41        74\n",
      "           9       0.30      0.13      0.18       127\n",
      "          10       0.32      0.22      0.26       220\n",
      "          11       0.50      0.42      0.45        84\n",
      "          12       0.36      0.13      0.20        30\n",
      "          13       0.37      0.33      0.35        84\n",
      "          14       0.59      0.59      0.59        74\n",
      "          15       0.82      0.86      0.84       288\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.48      0.47      0.47       116\n",
      "          18       0.63      0.75      0.68       169\n",
      "          19       0.00      0.00      0.00        16\n",
      "          20       0.52      0.52      0.52       120\n",
      "          21       0.00      0.00      0.00         8\n",
      "          22       0.40      0.09      0.15       109\n",
      "          23       0.00      0.00      0.00         7\n",
      "          24       0.51      0.67      0.58        46\n",
      "          25       0.43      0.41      0.42       108\n",
      "          26       0.35      0.32      0.33        92\n",
      "          27       0.56      0.68      0.61      1606\n",
      "\n",
      "    accuracy                           0.52      5427\n",
      "   macro avg       0.40      0.37      0.37      5427\n",
      "weighted avg       0.50      0.52      0.50      5427\n",
      "\n",
      "----------------------------------------\n",
      "STATS\n",
      "----------------------------------------\n",
      "Actual counter: Counter({27: 1606, 0: 504, 4: 318, 15: 288, 3: 286, 1: 252, 7: 233, 10: 220, 2: 197, 18: 169, 6: 139, 9: 127, 20: 120, 17: 116, 5: 114, 22: 109, 25: 108, 26: 92, 13: 84, 11: 84, 8: 74, 14: 74, 24: 46, 12: 30, 19: 16, 21: 8, 23: 7, 16: 6})\n",
      "Prediction counter: Counter({27: 1960, 0: 521, 1: 315, 15: 300, 4: 273, 7: 256, 3: 216, 18: 199, 2: 189, 10: 148, 6: 126, 20: 119, 17: 112, 25: 102, 5: 84, 26: 83, 13: 76, 14: 75, 11: 70, 24: 61, 9: 57, 8: 49, 22: 25, 12: 11})\n",
      "Mapping: {0: 'admiration', 1: 'amusement', 2: 'anger', 3: 'annoyance', 4: 'approval', 5: 'caring', 6: 'confusion', 7: 'curiosity', 8: 'desire', 9: 'disappointment', 10: 'disapproval', 11: 'disgust', 12: 'embarrassment', 13: 'excitement', 14: 'fear', 15: 'gratitude', 16: 'grief', 17: 'joy', 18: 'love', 19: 'nervousness', 20: 'optimism', 21: 'pride', 22: 'realization', 23: 'relief', 24: 'remorse', 25: 'sadness', 26: 'surprise', 27: 'neutral'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/brawat/miniconda3/envs/doc/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/brawat/miniconda3/envs/doc/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/brawat/miniconda3/envs/doc/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "df_test = get_performance(actual_og=dict_test_results['actual'], \n",
    "                          preds_og=dict_test_results['preds'], \n",
    "                          dict_mapping=id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a6a1694e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5427/5427 [00:00<00:00, 677293.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.63      0.62       503\n",
      "           1       0.71      0.87      0.78       252\n",
      "           2       0.45      0.43      0.44       197\n",
      "           3       0.27      0.20      0.23       284\n",
      "           4       0.34      0.29      0.32       316\n",
      "           5       0.30      0.21      0.25       113\n",
      "           6       0.31      0.28      0.30       137\n",
      "           7       0.46      0.51      0.48       231\n",
      "           8       0.51      0.34      0.41        73\n",
      "           9       0.31      0.13      0.19       126\n",
      "          10       0.33      0.22      0.27       216\n",
      "          11       0.51      0.42      0.46        84\n",
      "          13       0.38      0.33      0.35        84\n",
      "          14       0.65      0.60      0.62        73\n",
      "          15       0.83      0.86      0.84       288\n",
      "          17       0.50      0.47      0.48       115\n",
      "          18       0.63      0.75      0.68       169\n",
      "          20       0.53      0.52      0.52       120\n",
      "          22       0.42      0.09      0.15       106\n",
      "          25       0.46      0.45      0.46        98\n",
      "          26       0.36      0.32      0.34        92\n",
      "          27       0.56      0.68      0.61      1603\n",
      "\n",
      "    accuracy                           0.53      5280\n",
      "   macro avg       0.47      0.44      0.45      5280\n",
      "weighted avg       0.51      0.53      0.52      5280\n",
      "\n",
      "----------------------------------------\n",
      "STATS\n",
      "----------------------------------------\n",
      "Actual counter: Counter({27: 1603, 0: 503, 4: 316, 15: 288, 3: 284, 1: 252, 7: 231, 10: 216, 2: 197, 18: 169, 6: 137, 9: 126, 20: 120, 17: 115, 5: 113, 22: 106, 25: 98, 26: 92, 13: 84, 11: 84, 8: 73, 14: 73})\n",
      "Prediction counter: Counter({27: 1943, 0: 516, 1: 312, 15: 299, 4: 268, 7: 253, 3: 211, 18: 199, 2: 188, 10: 146, 6: 124, 20: 117, 17: 109, 25: 95, 26: 81, 5: 80, 13: 74, 11: 69, 14: 68, 9: 55, 8: 49, 22: 24})\n",
      "Mapping: {0: 'admiration', 1: 'amusement', 2: 'anger', 3: 'annoyance', 4: 'approval', 5: 'caring', 6: 'confusion', 7: 'curiosity', 8: 'desire', 9: 'disappointment', 10: 'disapproval', 11: 'disgust', 12: 'embarrassment', 13: 'excitement', 14: 'fear', 15: 'gratitude', 16: 'grief', 17: 'joy', 18: 'love', 19: 'nervousness', 20: 'optimism', 21: 'pride', 22: 'realization', 23: 'relief', 24: 'remorse', 25: 'sadness', 26: 'surprise', 27: 'neutral'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_test = get_performance(actual_og=dict_test_results['actual'], \n",
    "                          preds_og=dict_test_results['preds'], \n",
    "                          dict_mapping=id2label,\n",
    "                          avoid_labels=[12, 16, 19, 21, 23, 24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2d1a043f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5427/5427 [00:00<00:00, 458329.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64       489\n",
      "           1       0.72      0.88      0.79       251\n",
      "           2       0.48      0.45      0.46       191\n",
      "           3       0.30      0.20      0.24       274\n",
      "           4       0.36      0.30      0.33       304\n",
      "           5       0.31      0.22      0.26       110\n",
      "           6       0.32      0.29      0.31       133\n",
      "           7       0.49      0.53      0.51       221\n",
      "           9       0.33      0.15      0.20       117\n",
      "          10       0.34      0.23      0.28       205\n",
      "          15       0.84      0.87      0.85       285\n",
      "          17       0.55      0.49      0.52       110\n",
      "          18       0.66      0.75      0.70       169\n",
      "          20       0.57      0.55      0.56       113\n",
      "          22       0.43      0.11      0.17        93\n",
      "          25       0.48      0.49      0.48        90\n",
      "          27       0.59      0.70      0.64      1558\n",
      "\n",
      "    accuracy                           0.56      4713\n",
      "   macro avg       0.49      0.46      0.47      4713\n",
      "weighted avg       0.54      0.56      0.54      4713\n",
      "\n",
      "----------------------------------------\n",
      "STATS\n",
      "----------------------------------------\n",
      "Actual counter: Counter({27: 1558, 0: 489, 4: 304, 15: 285, 3: 274, 1: 251, 7: 221, 10: 205, 2: 191, 18: 169, 6: 133, 9: 117, 20: 113, 5: 110, 17: 110, 22: 93, 25: 90})\n",
      "Prediction counter: Counter({27: 1849, 0: 504, 1: 305, 15: 293, 4: 256, 7: 240, 18: 191, 3: 186, 2: 176, 10: 140, 6: 122, 20: 109, 17: 98, 25: 92, 5: 78, 9: 51, 22: 23})\n",
      "Mapping: {0: 'admiration', 1: 'amusement', 2: 'anger', 3: 'annoyance', 4: 'approval', 5: 'caring', 6: 'confusion', 7: 'curiosity', 8: 'desire', 9: 'disappointment', 10: 'disapproval', 11: 'disgust', 12: 'embarrassment', 13: 'excitement', 14: 'fear', 15: 'gratitude', 16: 'grief', 17: 'joy', 18: 'love', 19: 'nervousness', 20: 'optimism', 21: 'pride', 22: 'realization', 23: 'relief', 24: 'remorse', 25: 'sadness', 26: 'surprise', 27: 'neutral'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_test = get_performance(actual_og=dict_test_results['actual'], \n",
    "                          preds_og=dict_test_results['preds'], \n",
    "                          dict_mapping=id2label,\n",
    "                          avoid_labels=[8, 11, 12, 13, 14, 16, 19, 21, 23, 24, 26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6efeb6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_roberta = {}\n",
    "for each_ in [x.split('      ') for x in df_test.split('\\n')[2:-5]]:\n",
    "    dict_roberta[id2label[int(each_[1])]] = [float(each_[-2]) , int(each_[-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6356f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = open('goemotions_results.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "15f1d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_baseline = {}\n",
    "for each_ in baseline_results.split('\\n'):\n",
    "    dict_baseline[each_.split(' ')[0]] = each_.split(' ')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a9cd13f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Emotion: admiration\n",
      "============================================================\n",
      "Baseline: 0.65\n",
      "RoBERTa: 0.62\n",
      "Support: 504\n",
      "============================================================\n",
      "Emotion: amusement\n",
      "============================================================\n",
      "Baseline: 0.80\n",
      "RoBERTa: 0.78\n",
      "Support: 252\n",
      "============================================================\n",
      "Emotion: anger\n",
      "============================================================\n",
      "Baseline: 0.47\n",
      "RoBERTa: 0.44\n",
      "Support: 197\n",
      "============================================================\n",
      "Emotion: annoyance\n",
      "============================================================\n",
      "Baseline: 0.34\n",
      "RoBERTa: 0.22\n",
      "Support: 286\n",
      "============================================================\n",
      "Emotion: approval\n",
      "============================================================\n",
      "Baseline: 0.36\n",
      "RoBERTa: 0.31\n",
      "Support: 318\n",
      "============================================================\n",
      "Emotion: caring\n",
      "============================================================\n",
      "Baseline: 0.39\n",
      "RoBERTa: 0.24\n",
      "Support: 114\n",
      "============================================================\n",
      "Emotion: confusion\n",
      "============================================================\n",
      "Baseline: 0.37\n",
      "RoBERTa: 0.29\n",
      "Support: 139\n",
      "============================================================\n",
      "Emotion: curiosity\n",
      "============================================================\n",
      "Baseline: 0.54\n",
      "RoBERTa: 0.48\n",
      "Support: 233\n",
      "============================================================\n",
      "Emotion: desire\n",
      "============================================================\n",
      "Baseline: 0.49\n",
      "RoBERTa: 0.41\n",
      "Support: 74\n",
      "Added.\n",
      "============================================================\n",
      "Emotion: disappointment\n",
      "============================================================\n",
      "Baseline: 0.28\n",
      "RoBERTa: 0.18\n",
      "Support: 127\n",
      "============================================================\n",
      "Emotion: disapproval\n",
      "============================================================\n",
      "Baseline: 0.39\n",
      "RoBERTa: 0.26\n",
      "Support: 220\n",
      "============================================================\n",
      "Emotion: disgust\n",
      "============================================================\n",
      "Baseline: 0.45\n",
      "RoBERTa: 0.45\n",
      "Support: 84\n",
      "Added.\n",
      "============================================================\n",
      "Emotion: embarrassment\n",
      "============================================================\n",
      "Baseline: 0.43\n",
      "RoBERTa: 0.2\n",
      "Support: 30\n",
      "Added.\n",
      "============================================================\n",
      "Emotion: excitement\n",
      "============================================================\n",
      "Baseline: 0.34\n",
      "RoBERTa: 0.35\n",
      "Support: 84\n",
      "Added.\n",
      "============================================================\n",
      "Emotion: fear\n",
      "============================================================\n",
      "Baseline: 0.60\n",
      "RoBERTa: 0.59\n",
      "Support: 74\n",
      "Added.\n",
      "============================================================\n",
      "Emotion: gratitude\n",
      "============================================================\n",
      "Baseline: 0.86\n",
      "RoBERTa: 0.84\n",
      "Support: 288\n",
      "============================================================\n",
      "Emotion: grief\n",
      "============================================================\n",
      "Baseline: 0.00\n",
      "RoBERTa: 0.0\n",
      "Support: 6\n",
      "Added.\n",
      "============================================================\n",
      "Emotion: joy\n",
      "============================================================\n",
      "Baseline: 0.51\n",
      "RoBERTa: 0.47\n",
      "Support: 116\n",
      "============================================================\n",
      "Emotion: love\n",
      "============================================================\n",
      "Baseline: 0.78\n",
      "RoBERTa: 0.68\n",
      "Support: 169\n",
      "============================================================\n",
      "Emotion: nervousness\n",
      "============================================================\n",
      "Baseline: 0.35\n",
      "RoBERTa: 0.0\n",
      "Support: 16\n",
      "Added.\n",
      "============================================================\n",
      "Emotion: neutral\n",
      "============================================================\n",
      "Baseline: 0.68\n",
      "RoBERTa: 0.61\n",
      "Support: 1606\n",
      "============================================================\n",
      "Emotion: optimism\n",
      "============================================================\n",
      "Baseline: 0.51\n",
      "RoBERTa: 0.52\n",
      "Support: 120\n",
      "============================================================\n",
      "Emotion: pride\n",
      "============================================================\n",
      "Baseline: 0.36\n",
      "RoBERTa: 0.0\n",
      "Support: 8\n",
      "Added.\n",
      "============================================================\n",
      "Emotion: realization\n",
      "============================================================\n",
      "Baseline: 0.21\n",
      "RoBERTa: 0.15\n",
      "Support: 109\n",
      "============================================================\n",
      "Emotion: relief\n",
      "============================================================\n",
      "Baseline: 0.15\n",
      "RoBERTa: 0.0\n",
      "Support: 7\n",
      "Added.\n",
      "============================================================\n",
      "Emotion: remorse\n",
      "============================================================\n",
      "Baseline: 0.66\n",
      "RoBERTa: 0.58\n",
      "Support: 46\n",
      "Added.\n",
      "============================================================\n",
      "Emotion: sadness\n",
      "============================================================\n",
      "Baseline: 0.49\n",
      "RoBERTa: 0.42\n",
      "Support: 108\n",
      "============================================================\n",
      "Emotion: surprise\n",
      "============================================================\n",
      "Baseline: 0.50\n",
      "RoBERTa: 0.33\n",
      "Support: 92\n",
      "Added.\n"
     ]
    }
   ],
   "source": [
    "labels_to_avoid = []\n",
    "list_macro_f1_score = []\n",
    "for each_key in dict_baseline:\n",
    "    print('=='*30)\n",
    "    print('Emotion:', each_key)\n",
    "    print('=='*30)\n",
    "    print('Baseline:', dict_baseline[each_key])\n",
    "    print('RoBERTa:', dict_roberta[each_key][0])\n",
    "    print('Support:', dict_roberta[each_key][1])\n",
    "    if dict_roberta[each_key][1]<100:\n",
    "        labels_to_avoid.append(each_key)\n",
    "        print('Added.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "951fed1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 11, 12, 13, 14, 16, 19, 21, 23, 24, 26]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[key for key,val in id2label.items() if val in labels_to_avoid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "42c96da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['desire', 'disgust', 'embarrassment', 'excitement', 'fear', 'grief', 'nervousness', 'pride', 'relief', 'remorse', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "print(labels_to_avoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "253bd18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 16, 19, 21, 23, 24]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When the cut-off for support is around 50\n",
    "[key for key,val in id2label.items() if val in labels_to_avoid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b051e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e0aaf750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, tokenizer, out_dir):\n",
    "    # Take care of distributed/parallel training\n",
    "    os.mkdir(out_dir)\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model  \n",
    "    model_to_save.save_pretrained(out_dir)\n",
    "    tokenizer.save_pretrained(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f1c98886",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model=model, \n",
    "           tokenizer=tokenizer,\n",
    "           out_dir='roberta_goEmotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f703939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
